#######################
## Data processing
#######################

# Plate 1.1
plate1.1 <- read.csv("yield_data\\plate1.1.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.1_pdt <- plate1.1$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.1_pdt))
dim(plate.data) <- c(24,16)
plate.data1.1 <- t(plate.data)

# Plate 1.2
plate1.2 <- read.csv("yield_data\\plate1.2.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.2_pdt <- plate1.2$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.2_pdt))
dim(plate.data) <- c(24,16)
plate.data1.2 <- t(plate.data)

# Plate 1.3
plate1.3 <- read.csv("yield_data\\plate1.3.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.3_pdt <- plate1.3$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.3_pdt))
dim(plate.data) <- c(24,16)
plate.data1.3 <- t(plate.data)

# Plate 1.4
plate1.4 <- read.csv("yield_data\\plate1.4.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.4_pdt <- plate1.4$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.4_pdt))
dim(plate.data) <- c(24,16)
plate.data1.4 <- t(plate.data)

# stitch Plate 1 together into one 32x48 matrix
plate1.top <- cbind(plate.data1.1, plate.data1.2)
plate1.bottom <- cbind(plate.data1.3, plate.data1.4)
plate1 <- rbind(plate1.top, plate1.bottom)

# Plate 2.1
plate2.1 <- read.csv("yield_data\\plate2.1.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.1_pdt <- plate2.1$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.1_pdt))
dim(plate.data) <- c(24,16)
plate.data2.1 <- t(plate.data)

# Plate 2.2
plate2.2 <- read.csv("yield_data\\plate2.2.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.2_pdt <- plate2.2$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.2_pdt))
dim(plate.data) <- c(24,16)
plate.data2.2 <- t(plate.data)

# Plate 2.3
plate2.3 <- read.csv("yield_data\\plate2.3.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.3_pdt <- plate2.3$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.3_pdt))
dim(plate.data) <- c(24,16)
plate.data2.3 <- t(plate.data)

# Plate 2.4
plate2.4 <- read.csv("yield_data\\plate2.4.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.4_pdt <- plate2.4$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.4_pdt))
dim(plate.data) <- c(24,16)
plate.data2.4 <- t(plate.data)

# stitch Plate 2 together into one 32x48 matrix
plate2.top <- cbind(plate.data2.1, plate.data2.2)
plate2.bottom <- cbind(plate.data2.3, plate.data2.4)
plate2 <- rbind(plate2.top, plate2.bottom)

# Plate 3.1
plate3.1 <- read.csv("yield_data\\plate3.1.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.1_pdt <- plate3.1$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.1_pdt))
dim(plate.data) <- c(24,16)
plate.data3.1 <- t(plate.data)

# Plate 3.2
plate3.2 <- read.csv("yield_data\\plate3.2.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.2_pdt <- plate3.2$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.2_pdt))
dim(plate.data) <- c(24,16)
plate.data3.2 <- t(plate.data)

# Plate 3.3
plate3.3 <- read.csv("yield_data\\plate3.3.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.3_pdt <- plate3.3$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.3_pdt))
dim(plate.data) <- c(24,16)
plate.data3.3 <- t(plate.data)

# Plate 3.4
plate3.4 <- read.csv("yield_data\\plate3.4.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.4_pdt <- plate3.4$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.4_pdt))
dim(plate.data) <- c(24,16)
plate.data3.4 <- t(plate.data)

# stitch Plate 3 together into one 32x48 matrix
plate3.top <- cbind(plate.data3.1, plate.data3.2)
plate3.bottom <- cbind(plate.data3.3, plate.data3.4)
plate3 <- rbind(plate3.top, plate3.bottom)

# Remove empty rows/cols
plate1_nocontrols <- plate1[c(-1,-5,-9,-13,-20,-24,-28,-32), c(-16,-32,-48)] 
plate2_nocontrols <- plate2[, c(-16,-32,-48)]
plate3_nocontrols <- plate3[, c(-16,-32,-48)]
plate1_nocontrols_v <- as.vector(t(plate1_nocontrols))
plate2_nocontrols_v <- as.vector(t(plate2_nocontrols))
plate3_nocontrols_v <- as.vector(t(plate3_nocontrols))
yield_data <- c(plate1_nocontrols_v, plate2_nocontrols_v, plate3_nocontrols_v)

# Load output table generated by python script
output.table <- read.csv("yield_data\\output_table.csv", header=TRUE)

# Scaled variables
y <- as.data.frame(yield_data[-which(is.na(yield_data))]/100)
x <- as.data.frame(output.table[-which(is.na(yield_data)),])
#x <- as.data.frame(scale(output.table[-which(is.na(yield_data)),]))
tt <- (1:length(y[,1]))/length(y)

# Add three artificial descriptors for additives
xc <- x
set.seed(2134)
c1 <- factor(xc[,1])
c2 <- factor(xc[,3])
c3 <- factor(xc[,4])
levels(c1) <- runif(22)
levels(c2) <- rnorm(22)
levels(c3) <- runif(22)
xc <- cbind(cbind(as.numeric(c1),as.numeric(c2),as.numeric(c3)),xc)
colnames(xc)[1:3] <- c("add_new1","add_new2","add_new3")

xs <- xc[,c(4,23,50,60)]
colnames(xs) <- c("additive","aryl_halide","base","ligand")

a <- rep(NA,ncol(xs))
for (i in 1:ncol(xs)) a[i] <- length(unique(xs[,i]))
xcf <- matrix(NA,nrow(xs),sum(a))
b <- cumsum(a)
colnames(xcf) <- rep(colnames(xs),times=a)
colnum <- order(unique(xs[,1]))
for (i in 2:ncol(xs)) colnum <- c(colnum,order(unique(xs[,i])))
colnames(xcf) <- paste(colnames(xcf),colnum)
for (i in 1:nrow(xs))
{
  for (j in 1:length(a))
  {
    res <- rep(0, a[j])
    where <- match( xs[i,j], unique(xs[,j]) )
    res[ where ] <- 1 
    xcf[i,(max(b[j-1],0)+1):b[j]] <- res
  }
}
for (i in 1:length(b))
{
  ind <- match(xcf[,b[i]],1)==1
  xcf[ind,(max(b[i-1],0)+1):b[i]] <- -1
}
xcf <- xcf[,-b]
x.all <- xcf

# Identify label ijkl for yield
for (ijkl in 1:length(tt)) {
  add.i <- colnames(x.all)[which(x.all[ijkl,]!=0)][1]
  add.I <- sum(grepl("additive",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (add.I>1) add.i <- "additive 0"
  ary.j <- colnames(x.all)[which(x.all[ijkl,]!=0)][1+add.I]
  ary.J <- sum(grepl("aryl_halide",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (ary.J>1) ary.j <- "aryl_halide 0"
  bas.k <- colnames(x.all)[which(x.all[ijkl,]!=0)][1+add.I+ary.J]
  bas.K <- sum(grepl("base",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (bas.K>1) bas.k <- "base 0"
  lig.l <- colnames(x.all)[which(x.all[ijkl,]!=0)][1+add.I+ary.J+bas.K]
  lig.L <- sum(grepl("ligand",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (lig.L>1) lig.l <- "ligand 0"
  rownames(y)[ijkl] <- paste(add.i, ary.j, bas.k, lig.l, sep=":")
}
y.all <- y

# Mixed terms with 2-levels combinations
xx <- rep(1,nrow(xcf))
bb <- cumsum(a-1)
for (j in 1:3) {
  for (i in (max(bb[j-1],0)+1):bb[j]) {
    xxp <- xcf[,i]*xcf[,-c(1:bb[j])]
    colnames(xxp) <- paste(colnames(xcf)[i],colnames(xcf[,-c(1:bb[j])]),sep=":")
    xx <- cbind(xx,xxp)
  }
}
xx <- cbind(xcf,xx[,-1])
xx.all <- xx

# Mixed terms with 3-levels combinations
xcf1 <- xcf
colnames(xcf1) <- c(rep("additive",21),rep("aryl_halide",14),rep("base",2),rep("ligand",3))
xx1 <- xx[,-c(1:40)]

xxx <- rep(1,nrow(xcf))
ind <- rep(TRUE,ncol(xx1))
for (j in 1:2) {
  ind <- as.logical((!grepl(colnames(xcf1)[bb[j]],colnames(xx1)))*(ind))
  for (i in (max(bb[j-1],0)+1):bb[j]) {
    xxxp <- xcf[,i]*xx1[,ind]
    colnames(xxxp) <- paste(colnames(xcf)[i],colnames(xx1)[ind],sep=":")
    xxx <- cbind(xxx,xxxp)
  }
}
xxx <- cbind(xx,xxx[,-1])
xxx.all <- xxx

# Mixed terms with 4-levels combinations
xxx1 <- xxx[,-c(1:515)]

xxxx <- rep(NA,nrow(xcf))
for (i in 1:21) {
  xxxxp <- xcf[,i]*xxx1[,1597:1680]
  colnames(xxxxp) <- paste(colnames(xcf)[i],colnames(xxx1)[1597:1680],sep=":")
  xxxx <- cbind(xxxx,xxxxp)
}
xxxx <- cbind(xxx,xxxx[,-1])
xxxx.all <- xxxx



################################################################################
## Data Analysis on artificial ANOVA with two factors and two-way interactions  
################################################################################


print(dim(y))
print( colnames(xxxx))

# Fix levels of two factors
# Here we fix additive and base
fac1.lab <- "additive 7"
fac2.lab <- "base 0"

# Artificial response for two factors and two-way interactions
# There are 60 = 15 x 4 combinations for aryl and ligand
row2.all <- c()
for (ijkl in 1:dim(y.all)[1]) {
  # Label of four-way interaction
  ijkl.lab <- unlist(strsplit(rownames(y.all)[ijkl],split=":"))
  if ((is.element(fac1.lab,ijkl.lab))&(is.element(fac2.lab,ijkl.lab))) row2.all <- c(row2.all, ijkl)
}
Y <- as.data.frame(y.all[row2.all,1])      
rownames(Y) <- rownames(y.all)[row2.all]

dim(Y)

# Artificial design matrix for two factors and two-way interactions
# Here the matrix has 60 rows and 60 columns
X <- xxxx.all[row2.all,1:ncol(xx.all)]
col2.all <- c()
for (col in 1:ncol(xx.all)) {
  # Label of one/two/three/four-way interaction
  col.lab <- unlist(strsplit(colnames(xx.all)[col],split=":"))
  if (sum(grepl(strsplit(fac1.lab,split=" ")[[1]][1], unlist(strsplit(colnames(xx.all)[col],split=":")), fixed=TRUE))) col2.all <- c(col2.all, col)
  if (sum(grepl(strsplit(fac2.lab,split=" ")[[1]][1], unlist(strsplit(colnames(xx.all)[col],split=":")), fixed=TRUE))) col2.all <- c(col2.all, col)
}
X <- X[,-col2.all]

colnames(X)
dim(X)


X_all_main<-x.all ##have X_all_main for later


################### FUNCTIONS THAT I USE #####################


checkBlocks <- function(mat, u, l) {
  if (u + l != nrow(mat) || nrow(mat) != ncol(mat)) {
    stop("Input matrix is not square or does not match u + l.")
  }
  
  # Check upper-left u x u block
  upper_left_block <- mat[1:u, 1:u]
  if (any(upper_left_block != 0)) {
    non_zero_positions <- which(upper_left_block != 0, arr.ind = TRUE)
    cat("Non-zero entries in upper-left block:\n")
    for (i in 1:nrow(non_zero_positions)) {
      cat("Position:", non_zero_positions[i, ])
    }
  } else {
    cat("No non-zero entries in the upper-left block.\n")
  }
  
  # Check lower-right l x l block
  lower_right_block <- mat[(nrow(mat) - l + 1):nrow(mat), (ncol(mat) - l + 1):ncol(mat)]
  if (any(lower_right_block != 0)) {
    non_zero_positions <- which(lower_right_block != 0, arr.ind = TRUE)
    cat("Non-zero entries in lower-right block:\n")
    for (i in 1:nrow(non_zero_positions)) {
      cat("Position:", non_zero_positions[i, ] + c((nrow(mat) - l + 1), (ncol(mat) - l + 1)))
    }
  } else {
    cat("No non-zero entries in the lower-right block.\n")
  }
}

# Example usage:
# Create a 5x5 square matrix
#example_matrix <- matrix(c(1, 10, 3, 0, 0,
                           #0, 2, 0, 0, 0,
                           #0, 0, 0, 0, 0,
                           #0, 4, 0, 10, 5,
                           #7, 7, 7, 10, 0), nrow = 5, byrow = TRUE)

# Check blocks with u = 2 and l = 3
#checkBlocks(example_matrix, 3, 2)


r2 <- function(actual, predicted) {
  # Calculate the mean of the actual values
  mean_actual <- mean(actual)
  
  # Calculate the total sum of squares
  total_sum_squares <- sum((actual - mean_actual)^2)
  
  # Calculate the residual sum of squares
  residual_sum_squares <- sum((actual - predicted)^2)
  
  # Calculate R-squared
  r_squared <- 1 - (residual_sum_squares / total_sum_squares)
  
  return(r_squared)
}





pairwise_product <- function(A, B) {
  # Get the number of columns in each matrix
  ncol_A <- ncol(A)
  ncol_B <- ncol(B)
  
  # Initialize an empty list to store the pairwise products
  products <- list()
  
  # Loop through all combinations of columns
  for (i in 1:ncol_A) {
    for (j in 1:ncol_B) {
      # Calculate the pairwise product and store it in the list
      products[[length(products) + 1]] <- A[, i] * B[, j]
    }
  }
  
  # Combine the pairwise products into a single matrix
  result <- do.call(cbind, products)
  
  return(result)
}

create_pairwise_interactions <- function(X, num_categories_list) {
  num_factors <- length(num_categories_list)
  num_cols <- (sum(num_categories_list)^2- sum(num_categories_list^2))/2 ## sum ab= [(sum a)^2- sum a^2]/2
  
  # Initialize the new matrix for pairwise interactions
  pairwise_interactions <- matrix(0, nrow = nrow(X), ncol = num_cols)
  col_idx_start <- 1
  
  # Iterate over all pairs of different factors
  for (i in 1:(num_factors - 1)) {
    for (j in (i + 1):num_factors) {
      # Get the number of categories for factor i and factor j
      num_categories_i <- num_categories_list[i]
      num_categories_j <- num_categories_list[j]
      col_idx_final<-col_idx_start+num_categories_i*num_categories_j-1 #substract the one where w start
      
      # Extract columns corresponding to factor i and factor j
      if (i==1)
      {cols_i<-(1:num_categories_list[i])}
      else
      {
        cols_i <- (sum(num_categories_list[1:(i - 1)]) + 1):(sum(num_categories_list[1:i])) }
      
      cols_j <- (sum(num_categories_list[1:(j - 1)]) + 1):(sum(num_categories_list[1:j]))
      print('cols i')
      print(cols_i)
      print('colsj')
      print(cols_j)
      # Compute the pairwise interactions between factor i and factor j
      print("matrix i")
      print(matrix(X[,cols_i], ncol = length(cols_i)))
      pairwise_interaction <- pairwise_product(matrix(X[,cols_i], ncol = length(cols_i)), matrix(X[,cols_j], ncol = length(cols_j))  )
      print('a')
      # Store the pairwise interactions in the new matrix
      pairwise_interactions[, col_idx_start:col_idx_final] <- pairwise_interaction
      
      # Increment the column index
      col_idx_start<-col_idx_final+1
    }
  }
  
  return(pairwise_interactions)
}

# Example usage:
#X <- matrix(1:12, ncol = 4)
#pairwise_interactions <- create_pairwise_interactions(X,c(1,1,2))
#pairwise_interactions





###Puting matrix in suitable position for hiernet####

# Assuming X is your data frame
halide_columns <- c(
  "aryl_halide 12", "aryl_halide 6", "aryl_halide 9", "aryl_halide 15", "aryl_halide 3",
  "aryl_halide 5", "aryl_halide 4", "aryl_halide 8", "aryl_halide 14", "aryl_halide 7",
  "aryl_halide 13", "aryl_halide 2", "aryl_halide 1", "aryl_halide 10")

ligand_columns <- c("ligand 4", "ligand 3", "ligand 1")

X_halide <-  xxxx[, halide_columns, drop = FALSE]

X_ligand <- xxxx[, ligand_columns, drop = FALSE]



# Step 1: Add a new column "aryl_halide 11"
X_halide <- cbind(X_halide, "aryl_halide 11" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_halide[X_halide[, "aryl_halide 1"] == -1, "aryl_halide 11"] <- 1

# Step 3: Replace all -1 with 0 in the entire matrix
X_halide[X_halide == -1] <- 0

# Assuming X_ligand is your matrix
# Step 1: Add a new column "aryl_halide 11"
X_ligand <- cbind(X_ligand, "ligand 2" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_ligand[X_ligand[, "ligand 1"] == -1, "ligand 2"] <- 1

# Step 3: Replace all -1 with 0 in the entire matrix
X_ligand[X_ligand == -1] <- 0

#Check the transformations worked
#rowSums( X_ligand ) 
#rowSums(X_halide)


print(dim(X_halide))

X_main <- cbind(X_halide, X_ligand)
dim(X_main)
rowSums(X_main)




#### PREPARE ALSO X_all_MAIN (i.e. get rid of -1 and add all columns #### (Think if this can be improved

X_all_main<-x.all ##have X_all_main for later

# Step 1: Add a new column "aryl_halide 11"
X_all_main <- cbind(X_all_main, "aryl_halide 11" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_all_main[X_all_main[, "aryl_halide 1"] == -1, "aryl_halide 11"] <- 1




# Step 1: Add a new column "aryl_halide 11"
X_all_main <- cbind(X_all_main, "ligand 2" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_all_main[X_all_main[, "ligand 1"] == -1, "ligand 2"] <- 1



# Step 1: Add a new column "aryl_halide 11"
X_all_main <- cbind(X_all_main, "additive 15" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_all_main[X_all_main[, "additive 1"] == -1, "additive 15"] <- 1



# Step 1: Add a new column "aryl_halide 11"
X_all_main <- cbind(X_all_main, "base 3" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_all_main[X_all_main[, "base 1"] == -1, "base 3"] <- 1

# Step 3: Replace all -1 with 0 in the entire matrix
X_all_main[X_all_main == -1] <- 0

#Check the transformations worked
rowSums( X_all_main ) 
colnames(X_all_main)



# Order the column names
sorted_column_names <- sort(colnames(X_all_main))

# Reorder the columns of your data frame using the sorted column names
X_all_main <- X_all_main[, sorted_column_names]





#################### USE HIERNET PACKAGE ######################
library(Metrics)

library(hierNet)
library(caret)
library(dplyr)
library(Metrics)

names(y)[ncol(y)] <- "yield"
main_data <- cbind(X_main, y$yield)

dim(main_data)


names(main_data)[ncol(main_data)] <- "yield" #name the y column




##TRAIN TEST SPLIT
index <- createDataPartition(y = y$yield, p = 0.7, list = FALSE)
train_data <- main_data [index,]
test_data <- main_data [-index,]



# Separate X_train, X_test, y_train, y_test
X_train <- train_data[, -ncol(train_data)]
y_train <- train_data[, ncol(train_data)]
X_test <- test_data[, -ncol(test_data)]
y_test <- test_data[, ncol(test_data)]

y_train<-y_train*100
y_test<-y_test*100

print(dim(X_train))

print(dim(X_test))
print(length(y_train))
print(length(y_test))





print("-----Hiernet library on train-----")
##On train
fit=hierNet(X_train,y_train,lam=20, diagonal = FALSE)
yhat=predict(fit,X_train)
fit$bp
fit $bn
rmse(y_train, yhat)
r2(y_train, yhat)
#checkBlocks(fit$th,15,4) ##check if interations that should be 0 are 0 
fit
print(max(yhat))
max(y_train)
max(yhat)


##Create interactions- maybe not needed###
create_interactions <- function(X) {
  n_features <- ncol(X)
  interaction_terms <- matrix(0, nrow = nrow(X), ncol = n_features * (n_features - 1) / 2)
  col_counter <- 1
  
  for (i in 1:(n_features - 1)) {
    for (j in (i + 1):n_features) {
      interaction_terms[, col_counter] <- X[, i] * X[, j]
      col_counter <- col_counter + 1
    }
  }
  
  return(cbind(X, interaction_terms))
}

X_train_interactions <- create_interactions(X_train)
X_test_interactions <- create_interactions(X_test)
###############


#####################DO the analysis on whole data with pairwise interacions################################

index <- createDataPartition(y = y$yield, p = 0.7, list = FALSE)
train_data <- main_data [index,]
test_data <- main_data [-index,]



# Separate X_train, X_test, y_train, y_test
X_all_train <- X_all_main[index, ]
y_train <- y[index, ]
X_all_test <- X_all_main[-index,]
y_test <- y[-index, ]



y_train<-y_train*100
y_test<-y_test*100

max(y_train)

print(dim(X_all_train))

print(dim(X_all_test))
print(length(y_train))
print(length(y_test))


colnames(X_all_train)


##On train

lamhat=80
fit=hierNet(X_all_train,y_train, lam = lamhat, diagonal = FALSE)
yhat=predict(fit,X_all_test)
print("-----Library hiernet-----")
print(paste("rmse:",rmse(y_test, yhat)))
print(paste("r2:", r2(y_test, yhat)))
fit
#checkBlocks(fit$th,15,4)

max(yhat)
max(y_test)
print("------------")

################## DO THE SAME WITH MY HIERNET

source("WeakHierNet_Class_corrected.R")
print('My weakhiernet')

myWeakHierNet<-WeakHierNet (X=X_all_train, Beta_plus_init=matrix(0.3,nrow = dim(X_all_train)[2], ncol = 1), Beta_minus_init=matrix(0.1,nrow = dim(X_all_train)[2], ncol = 1), 
              Theta_init=matrix(0, ncol = dim(X_all_train)[2], nrow = dim(X_all_train)[2]), y=y_train, lambda=80, t=0.0001, tol=1e-8, 
              max_iter=150, eps=1e-8 )  #Increase max iter if needed or decrease tol 

# Fit the model
fitted=myWeakHierNet$fit(X=X_all_train, Beta_plus_init=matrix(0.3,nrow = dim(X_all_train)[2], ncol = 1), Beta_minus_init=matrix(0.1,nrow = dim(X_all_train)[2], ncol = 1), 
                         Theta_init=matrix(0, ncol = dim(X_all_train)[2], nrow = dim(X_all_train)[2]), y=y_train, lambda=80, t=0.0001, tol=1e-8, 
                         max_iter=150, eps=1e-8 )

# Make predictions
new_X <- X_all_test
predictions <- myWeakHierNet$predict(fitted, as.matrix(new_X))

myWeakHierNet$R2_score(self=fitted, new_X= as.matrix(new_X), y_true = y_test, verbose = TRUE)

fitted






###########################################################################################################





############################# USE MY CORRECTED CLASS ##########################################
source("WeakHierNet_Class_corrected.R")

Beta_plus_init=matrix(0,nrow = dim(X_all_train)[2], ncol = 1)
Beta_minus_init=matrix(0,nrow = dim(X_all_train)[2], ncol = 1)
Theta_init=matrix(0, ncol = dim(X_all_train)[2], nrow = dim(X_all_train)[2])
lambda=80
t=0.00001
tol = 1e-5

myWeakHierNet<-WeakHierNet (X=X_all_train, Beta_plus_init= Beta_plus_init, Beta_minus_init=Beta_minus_init, 
                            Theta_init = Theta_init, y=y_train, lambda=lambda, t=t, tol=tol, 
                            max_iter=100, eps=1e-8 ) 



# Fit the model
fitted=myWeakHierNet$fit(X=X_all_train, y=y_train, lambda=lambda, t = t, tol = tol, max_iter = 100, eps = 1e-8,
                         Beta_plus_init = Beta_plus_init,Beta_minus_init =  Beta_minus_init, Theta_init =  Theta_init)
fitted
# Make predictions
#y_pred=myWeakHierNet$predict(fitted, X_all_train)
#y_pred
#scale(y_train,center = TRUE, scale= FALSE)

myWeakHierNet$R2_score(self=fitted, new_X= as.matrix(X_all_test), y_true = y_test, verbose = TRUE)

###########################################################################################################



###CONCLUSIONS 

##It seems that there are no problems due to considering all pairs interactions bc for high enough lambda tho ones that should be 0 by default go to 0
##It has around 0.56 r2 score on both training and test set and rmse around 0.18
## It works better than a linear reg that does not consider interactions. It works similar to linear reg with all interactions. 
## It works much better on the entire data (around r2 = 0.856)


##de facut !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

###vezi daca Z trebuie scaled in ambele modele !!!!!!!!!!!!!!!!!!!!!!!!!!


swap_increase <- function(x, y) {
  if (x>y)
 {temp <- x
  x <- y
  y <- temp}
  return(list(x = x, y = y))
}

find_index_group <- function(lst, num) {
  if (num <=lst[1] && num>0)
  {return (1)}
  total_sum <- 0
  for (i in seq_along(lst)) {
    total_sum <- total_sum + lst[i]
    if (num > total_sum && num <= total_sum + lst[i + 1]) {
      return(i+1)
    }
  }
  print("returned NA")
  return(NA)  # If no such index is found
}

# Example usage
my_list <- c(1,1,1)
my_number <- 3
index <- find_index_group(my_list, my_number)
if (!is.na(index)) {
  cat("Index found:", index, "\n")
} else {
  cat("No such index found\n")
}



interaction_ab<-function(idx_a, idx_b, num_categories_list=c(22,15,3,4), main_lengths=44)
{partial_sums=rep(0,length(num_categories_list))

#Will use to compute idx
for (i in c(1:length(num_categories_list)) )
{partial_sums[i]<-sum(num_categories_list[1:i])}

befores=rep(0,length(num_categories_list))
for (i in c(2:length(num_categories_list)) )
befores[i]<- befores[i-1]+num_categories_list[i-1]*(sum(num_categories_list)-partial_sums[i-1])


if (idx_a>idx_b)
{ab=swap_increase(idx_a,idx_b)
idx_a=ab$x#smaller one
idx_b=ab$y}#bigger one
  
group_a<-find_index_group(num_categories_list,idx_a) # i.e 2 from 4 groups
group_b<-find_index_group(num_categories_list, idx_b)

if (group_a==1)
{positions_before_a<-(idx_a-1)*(sum(num_categories_list)-partial_sums[group_a])}
else if (group_a>1){
positions_before_a<-befores[group_a]+(idx_a-partial_sums[group_a-1]-1)*(sum(num_categories_list)-partial_sums[group_a])
}
positions_from_b<-idx_b-partial_sums[group_a]




if (group_a==group_b){print("There are interactions from same feature, not ok!")}

idx_ab<-positions_before_a +positions_from_b

return (idx_ab+main_lengths)}

print(interaction_ab(idx_a=25,idx_b=44))

create_all_interactions<- function( X_main,num_categories_list=c(22,15,3,4), main_lengths=44) #maybe optimize and use this only
{Beta_interaction_list<-c()
X_all<-X_main
for (idx_a in c(1:sum(num_categories_list[1:length(num_categories_list)-1])) )
  {
 group_a<-find_index_group(num_categories_list,idx_a)
 for (idx_b in c(sum(num_categories_list[1:group_a]) :main_lengths) )

   {
  group_b<-find_index_group(num_categories_list,idx_b)
  if (group_b != group_a)
  {

  X_all<-cbind(X_all,X_all[,idx_a]*X_all[,idx_b]) 
  idx_ab<-interaction_ab(idx_a, idx_b,num_categories_list, main_lengths)
  Beta_interaction_list<- cbind(Beta_interaction_list,c(idx_a, idx_b, idx_ab))
}}}
return (list("X"=X_all, "beta_interactions"=Beta_interaction_list))
}

X<-matrix(c(1,2,3,4,5,6,7,8,9,10,11,12), nrow = 3)
print(create_all_interactions(X_main=X,num_categories_list=c(1,2,1),main_lengths=4)) 

################## USE CAP WITH GENERAL OPTIMIZATION #####################
#prep data

p<-ncol(X_all_train)
p

X_train_cap<-X_all_train
X_train_cap<-create_all_interactions(X_train_cap)$X
beta_interactions<-create_all_interactions(X_train_cap)$beta_interactions
y_train_cap<-y_train
y_scaled_train<-scale(y_train, scale=FALSE)

X_test_cap<-X_all_test
X_test_cap<-create_all_interactions(X_test_cap)$X
y_test_cap<-y_test
y_scaled_test<-scale(y_test,scale=FALSE)

print(beta_interactions[3,])

print(dim(X_train_cap))
#use the minimizer
lambda <- 0
cap <- function(beta, X, y,beta_interactions, lambda=0) {
  result <- (1/dim(X)[1]) * sum((y - X %*% beta)^2)  
  for (i in c(1:ncol(beta_interactions)) )
   { 
    result<-result+lambda*max(abs( beta[beta_interactions[,i]] )) ## add terms like (b1 b2 b12)
    result<-result+ lambda* abs(beta[beta_interactions[3,i] ]) # add all terms like b12
    
  }
  print(result)
  return(result)
}

gradient_max_abs <- function(b) {
  abs_values <- abs(b)
  max_abs <- max(abs_values)
  gradient <- ifelse(abs_values == max_abs, sign(b), 0)
  return(gradient)
}

# Test the function

a=matrix(c(1,2,3,4), nrow = 2)
b=c(1,2,3,4)
b[a[,2]]<-c(1,1)
b


gradient_cap<- function(beta, X, y,beta_interactions, lambda=0)
{gr<-2/dim(X)[1] * ( t(X)%*%(X%*%beta-y) )
for (i in c(1:ncol(beta_interactions)) )
{ 
  gr[beta_interactions[,i]]<- gr[beta_interactions[,i]]+lambda*gradient_max_abs(beta[beta_interactions[,i]])## add terms like (b1 b2 b12)
  gr[beta_interactions[3,i]]<-  gr[beta_interactions[3,i]]+ lambda* sign(beta[beta_interactions[3,i] ]) # add all terms like b12
}
return(gr)
}
gradient_cap(initial_beta,X_train_cap,y_scaled_train,beta_interactions,1)


# Initial guess for beta
initial_beta <-rnorm(ncol(X_train_cap), mean = 0, sd = 1)
#initial_beta <-rnorm(ncol(X_train_cap), mean = 0, sd = 0)

lambda<-10
### USE OPTIM FUNCTION /nlm
# Call optim to minimize the function
#opt_result <- optim(par = initial_beta, fn = cap, gr=gradient_cap, X = X_train_cap, y = y_scaled_train, lambda=lambda,beta_interactions = beta_interactions, method="BFGS",control = list(maxit = 100))
#opt_result<-nlm(f = function(beta) cap(beta, X_train_cap, y_scaled_train, beta_interactions, lambda = lambda), p = initial_beta, iterlim = 12)
#opt_result
# Extract the optimal beta
#optimal_beta <- opt_result$par
#optimal_beta<-opt_result$estimate


#print("Using optim:")
#print("beta")
#print(optimal_beta)
#print("r2 train")
#print(r2(y_scaled_train,X_train_cap%*%optimal_beta))
#print("r2 test")
#print(r2(y_scaled_test, X_test_cap%*%optimal_beta))
#print(X_all_train%*%optimal_beta)


#####USE NLOPT#########
library(nloptr)
# Define optimization problem
lambda<-1
#opt_problem <- nloptr(
  #x0 = initial_beta,
  #eval_f = function(beta) cap(beta, X_train_cap, y_scaled_train, beta_interactions, lambda),
  #eval_grad_f= function(beta) gradient_cap(beta, X_train_cap, y_scaled_train, beta_interactions, lambda),
  #opts = list(algorithm = "NLOPT_LD_LBFGS_NOCEDAL", maxeval = 800)
#)
# Extract the optimal parameters (beta)
#optimal_beta <- opt_problem$solution

#print("Using optim:")



# Get the optimized parameters
optimized_beta <- result$target$values()[[1]]

# Print the optimized parameters
print(optimized_beta)
print("beta")
print(optimal_beta)
print("r2 train")
print(r2(y_scaled_train,X_train_cap%*%optimal_beta))
print("r2 test")
print(r2(y_scaled_test, X_test_cap%*%optimal_beta))


#Use nlminb#############
# Define your function

# Set initial values
#initial_beta <- rep(1, ncol(X_train_cap))  # Assuming X is your design matrix
#initial_beta <-rnorm(ncol(X_train_cap), mean = 0, sd = 1)

#lambda <- 0.1  # Your lambda value for regularization

# Define lower and upper bounds for beta
#lower_bound <- rep(-1000, length(initial_beta))
#upper_bound <- rep(1000, length(initial_beta))

# Define control parameters
#control_params <- list(iter.max = 200,step.min=10, step.max=100)  # Change maxeval to your desired maximum number of function evaluations

# Optimize using nlminb()
#opt_result <- nlminb(start = initial_beta, objective = cap,gradient=gradient_cap, X = X_train_cap, y = y_scaled_train, beta_interactions = beta_interactions, lambda = lambda, lower = lower_bound, upper = upper_bound, control = control_params)

# Extract the optimized beta values
#optimal_beta <- opt_result$par


print("Using optim:")
print("beta")
print(optimal_beta)
print("r2 train")
print(r2(y_scaled_train,X_train_cap%*%optimal_beta))
print("r2 test")
print(r2(y_scaled_test, X_test_cap%*%optimal_beta))
#print(X_all_train%*%optimal_beta)
######





#### USE CVRX

suppressWarnings(library(CVXR, warn.conflicts=FALSE))


lambda<-0
# Use cvxr to optimize beta
beta <- Variable(ncol(X_train_cap))

problem <- Problem(Minimize(cap(beta, X_train_cap, y_train, beta_interactions ,lambda=lambda)))
result <- solve(problem,control = list(max_iters = 10))

# Get the optimized beta values
optimized_beta <- result$getValue(beta)
print("Using cvrx:")
print(optimized_beta)

y_train_pred=X_train_cap%*%optimal_beta
print(r2(y_train, y_train_pred))








# Load necessary library for linear regression
library(stats)
# Assuming X_all_train is your feature matrix and y_train is your target vector
# Convert your data into a data frame
data <- data.frame(X_train_cap, y_train)

# Fit a linear regression model
lm_model <- lm(y_train ~ ., data)

# Predict the target values
predictions <- predict(lm_model, data)

# Compute R-squared score
r_squared <- summary(lm_model)$r.squared

print(r_squared)
coef(lm_model)





















