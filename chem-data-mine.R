#######################
## Data processing
#######################

# Plate 1.1
plate1.1 <- read.csv("yield_data\\plate1.1.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.1_pdt <- plate1.1$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.1_pdt))
dim(plate.data) <- c(24,16)
plate.data1.1 <- t(plate.data)

# Plate 1.2
plate1.2 <- read.csv("yield_data\\plate1.2.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.2_pdt <- plate1.2$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.2_pdt))
dim(plate.data) <- c(24,16)
plate.data1.2 <- t(plate.data)

# Plate 1.3
plate1.3 <- read.csv("yield_data\\plate1.3.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.3_pdt <- plate1.3$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.3_pdt))
dim(plate.data) <- c(24,16)
plate.data1.3 <- t(plate.data)

# Plate 1.4
plate1.4 <- read.csv("yield_data\\plate1.4.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.4_pdt <- plate1.4$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.4_pdt))
dim(plate.data) <- c(24,16)
plate.data1.4 <- t(plate.data)

# stitch Plate 1 together into one 32x48 matrix
plate1.top <- cbind(plate.data1.1, plate.data1.2)
plate1.bottom <- cbind(plate.data1.3, plate.data1.4)
plate1 <- rbind(plate1.top, plate1.bottom)

# Plate 2.1
plate2.1 <- read.csv("yield_data\\plate2.1.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.1_pdt <- plate2.1$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.1_pdt))
dim(plate.data) <- c(24,16)
plate.data2.1 <- t(plate.data)

# Plate 2.2
plate2.2 <- read.csv("yield_data\\plate2.2.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.2_pdt <- plate2.2$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.2_pdt))
dim(plate.data) <- c(24,16)
plate.data2.2 <- t(plate.data)

# Plate 2.3
plate2.3 <- read.csv("yield_data\\plate2.3.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.3_pdt <- plate2.3$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.3_pdt))
dim(plate.data) <- c(24,16)
plate.data2.3 <- t(plate.data)

# Plate 2.4
plate2.4 <- read.csv("yield_data\\plate2.4.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.4_pdt <- plate2.4$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.4_pdt))
dim(plate.data) <- c(24,16)
plate.data2.4 <- t(plate.data)

# stitch Plate 2 together into one 32x48 matrix
plate2.top <- cbind(plate.data2.1, plate.data2.2)
plate2.bottom <- cbind(plate.data2.3, plate.data2.4)
plate2 <- rbind(plate2.top, plate2.bottom)

# Plate 3.1
plate3.1 <- read.csv("yield_data\\plate3.1.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.1_pdt <- plate3.1$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.1_pdt))
dim(plate.data) <- c(24,16)
plate.data3.1 <- t(plate.data)

# Plate 3.2
plate3.2 <- read.csv("yield_data\\plate3.2.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.2_pdt <- plate3.2$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.2_pdt))
dim(plate.data) <- c(24,16)
plate.data3.2 <- t(plate.data)

# Plate 3.3
plate3.3 <- read.csv("yield_data\\plate3.3.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.3_pdt <- plate3.3$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.3_pdt))
dim(plate.data) <- c(24,16)
plate.data3.3 <- t(plate.data)

# Plate 3.4
plate3.4 <- read.csv("yield_data\\plate3.4.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.4_pdt <- plate3.4$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.4_pdt))
dim(plate.data) <- c(24,16)
plate.data3.4 <- t(plate.data)

# stitch Plate 3 together into one 32x48 matrix
plate3.top <- cbind(plate.data3.1, plate.data3.2)
plate3.bottom <- cbind(plate.data3.3, plate.data3.4)
plate3 <- rbind(plate3.top, plate3.bottom)

# Remove empty rows/cols
plate1_nocontrols <- plate1[c(-1,-5,-9,-13,-20,-24,-28,-32), c(-16,-32,-48)] 
plate2_nocontrols <- plate2[, c(-16,-32,-48)]
plate3_nocontrols <- plate3[, c(-16,-32,-48)]
plate1_nocontrols_v <- as.vector(t(plate1_nocontrols))
plate2_nocontrols_v <- as.vector(t(plate2_nocontrols))
plate3_nocontrols_v <- as.vector(t(plate3_nocontrols))
yield_data <- c(plate1_nocontrols_v, plate2_nocontrols_v, plate3_nocontrols_v)

# Load output table generated by python script
output.table <- read.csv("yield_data\\output_table.csv", header=TRUE)

# Scaled variables
y <- as.data.frame(yield_data[-which(is.na(yield_data))]/100)
x <- as.data.frame(output.table[-which(is.na(yield_data)),])
#x <- as.data.frame(scale(output.table[-which(is.na(yield_data)),]))
tt <- (1:length(y[,1]))/length(y)

# Add three artificial descriptors for additives
xc <- x
set.seed(2134)
c1 <- factor(xc[,1])
c2 <- factor(xc[,3])
c3 <- factor(xc[,4])
levels(c1) <- runif(22)
levels(c2) <- rnorm(22)
levels(c3) <- runif(22)
xc <- cbind(cbind(as.numeric(c1),as.numeric(c2),as.numeric(c3)),xc)
colnames(xc)[1:3] <- c("add_new1","add_new2","add_new3")

xs <- xc[,c(4,23,50,60)]
colnames(xs) <- c("additive","aryl_halide","base","ligand")

a <- rep(NA,ncol(xs))
for (i in 1:ncol(xs)) a[i] <- length(unique(xs[,i]))
xcf <- matrix(NA,nrow(xs),sum(a))
b <- cumsum(a)
colnames(xcf) <- rep(colnames(xs),times=a)
colnum <- order(unique(xs[,1]))
for (i in 2:ncol(xs)) colnum <- c(colnum,order(unique(xs[,i])))
colnames(xcf) <- paste(colnames(xcf),colnum)
for (i in 1:nrow(xs))
{
  for (j in 1:length(a))
  {
    res <- rep(0, a[j])
    where <- match( xs[i,j], unique(xs[,j]) )
    res[ where ] <- 1 
    xcf[i,(max(b[j-1],0)+1):b[j]] <- res
  }
}
for (i in 1:length(b))
{
  ind <- match(xcf[,b[i]],1)==1
  xcf[ind,(max(b[i-1],0)+1):b[i]] <- -1
}
xcf <- xcf[,-b]
x.all <- xcf

# Identify label ijkl for yield
for (ijkl in 1:length(tt)) {
  add.i <- colnames(x.all)[which(x.all[ijkl,]!=0)][1]
  add.I <- sum(grepl("additive",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (add.I>1) add.i <- "additive 0"
  ary.j <- colnames(x.all)[which(x.all[ijkl,]!=0)][1+add.I]
  ary.J <- sum(grepl("aryl_halide",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (ary.J>1) ary.j <- "aryl_halide 0"
  bas.k <- colnames(x.all)[which(x.all[ijkl,]!=0)][1+add.I+ary.J]
  bas.K <- sum(grepl("base",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (bas.K>1) bas.k <- "base 0"
  lig.l <- colnames(x.all)[which(x.all[ijkl,]!=0)][1+add.I+ary.J+bas.K]
  lig.L <- sum(grepl("ligand",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (lig.L>1) lig.l <- "ligand 0"
  rownames(y)[ijkl] <- paste(add.i, ary.j, bas.k, lig.l, sep=":")
}
y.all <- y

# Mixed terms with 2-levels combinations
xx <- rep(1,nrow(xcf))
bb <- cumsum(a-1)
for (j in 1:3) {
  for (i in (max(bb[j-1],0)+1):bb[j]) {
    xxp <- xcf[,i]*xcf[,-c(1:bb[j])]
    colnames(xxp) <- paste(colnames(xcf)[i],colnames(xcf[,-c(1:bb[j])]),sep=":")
    xx <- cbind(xx,xxp)
  }
}
xx <- cbind(xcf,xx[,-1])
xx.all <- xx

# Mixed terms with 3-levels combinations
xcf1 <- xcf
colnames(xcf1) <- c(rep("additive",21),rep("aryl_halide",14),rep("base",2),rep("ligand",3))
xx1 <- xx[,-c(1:40)]

xxx <- rep(1,nrow(xcf))
ind <- rep(TRUE,ncol(xx1))
for (j in 1:2) {
  ind <- as.logical((!grepl(colnames(xcf1)[bb[j]],colnames(xx1)))*(ind))
  for (i in (max(bb[j-1],0)+1):bb[j]) {
    xxxp <- xcf[,i]*xx1[,ind]
    colnames(xxxp) <- paste(colnames(xcf)[i],colnames(xx1)[ind],sep=":")
    xxx <- cbind(xxx,xxxp)
  }
}
xxx <- cbind(xx,xxx[,-1])
xxx.all <- xxx

# Mixed terms with 4-levels combinations
xxx1 <- xxx[,-c(1:515)]

xxxx <- rep(NA,nrow(xcf))
for (i in 1:21) {
  xxxxp <- xcf[,i]*xxx1[,1597:1680]
  colnames(xxxxp) <- paste(colnames(xcf)[i],colnames(xxx1)[1597:1680],sep=":")
  xxxx <- cbind(xxxx,xxxxp)
}
xxxx <- cbind(xxx,xxxx[,-1])
xxxx.all <- xxxx



################################################################################
## Data Analysis on artificial ANOVA with two factors and two-way interactions  
################################################################################


print(dim(y))
print( colnames(xxxx))

# Fix levels of two factors
# Here we fix additive and base
fac1.lab <- "additive 7"
fac2.lab <- "base 0"

# Artificial response for two factors and two-way interactions
# There are 60 = 15 x 4 combinations for aryl and ligand
row2.all <- c()
for (ijkl in 1:dim(y.all)[1]) {
  # Label of four-way interaction
  ijkl.lab <- unlist(strsplit(rownames(y.all)[ijkl],split=":"))
  if ((is.element(fac1.lab,ijkl.lab))&(is.element(fac2.lab,ijkl.lab))) row2.all <- c(row2.all, ijkl)
}
Y <- as.data.frame(y.all[row2.all,1])      
rownames(Y) <- rownames(y.all)[row2.all]

dim(Y)

# Artificial design matrix for two factors and two-way interactions
# Here the matrix has 60 rows and 60 columns
X <- xxxx.all[row2.all,1:ncol(xx.all)]
col2.all <- c()
for (col in 1:ncol(xx.all)) {
  # Label of one/two/three/four-way interaction
  col.lab <- unlist(strsplit(colnames(xx.all)[col],split=":"))
  if (sum(grepl(strsplit(fac1.lab,split=" ")[[1]][1], unlist(strsplit(colnames(xx.all)[col],split=":")), fixed=TRUE))) col2.all <- c(col2.all, col)
  if (sum(grepl(strsplit(fac2.lab,split=" ")[[1]][1], unlist(strsplit(colnames(xx.all)[col],split=":")), fixed=TRUE))) col2.all <- c(col2.all, col)
}
X <- X[,-col2.all]

colnames(X)
dim(X)


X_all_main<-x.all ##have X_all_main for later


################### FUNCTIONS THAT I USE #####################

r2 <- function(actual, predicted) {
  # Calculate the mean of the actual values
  mean_actual <- mean(actual)
  
  # Calculate the total sum of squares
  total_sum_squares <- sum((actual - mean_actual)^2)
  
  # Calculate the residual sum of squares
  residual_sum_squares <- sum((actual - predicted)^2)
  
  # Calculate R-squared
  r_squared <- 1 - (residual_sum_squares / total_sum_squares)
  
  return(r_squared)
}


checkBlocks <- function(mat, u, l) {
  if (u + l != nrow(mat) || nrow(mat) != ncol(mat)) {
    stop("Input matrix is not square or does not match u + l.")
  }
  
  # Check upper-left u x u block
  upper_left_block <- mat[1:u, 1:u]
  if (any(upper_left_block != 0)) {
    non_zero_positions <- which(upper_left_block != 0, arr.ind = TRUE)
    cat("Non-zero entries in upper-left block:\n")
    for (i in 1:nrow(non_zero_positions)) {
      cat("Position:", non_zero_positions[i, ])
    }
  } else {
    cat("No non-zero entries in the upper-left block.\n")
  }
  
  # Check lower-right l x l block
  lower_right_block <- mat[(nrow(mat) - l + 1):nrow(mat), (ncol(mat) - l + 1):ncol(mat)]
  if (any(lower_right_block != 0)) {
    non_zero_positions <- which(lower_right_block != 0, arr.ind = TRUE)
    cat("Non-zero entries in lower-right block:\n")
    for (i in 1:nrow(non_zero_positions)) {
      cat("Position:", non_zero_positions[i, ] + c((nrow(mat) - l + 1), (ncol(mat) - l + 1)))
    }
  } else {
    cat("No non-zero entries in the lower-right block.\n")
  }
}

# Example usage:
# Create a 5x5 square matrix
#example_matrix <- matrix(c(1, 10, 3, 0, 0,
                           #0, 2, 0, 0, 0,
                           #0, 0, 0, 0, 0,
                           #0, 4, 0, 10, 5,
                           #7, 7, 7, 10, 0), nrow = 5, byrow = TRUE)

# Check blocks with u = 2 and l = 3
#checkBlocks(example_matrix, 3, 2)




#######################################################

r2 <- function(actual, predicted) {
  # Calculate the mean of the actual values
  mean_actual <- mean(actual)
  
  # Calculate the total sum of squares
  total_sum_squares <- sum((actual - mean_actual)^2)
  
  # Calculate the residual sum of squares
  residual_sum_squares <- sum((actual - predicted)^2)
  
  # Calculate R-squared
  r_squared <- 1 - (residual_sum_squares / total_sum_squares)
  
  return(r_squared)
}

#### This should be run only once ######################
###Puting matrix in suitable position for hiernet####

# Assuming X is your data frame
halide_columns <- c(
  "aryl_halide 12", "aryl_halide 6", "aryl_halide 9", "aryl_halide 15", "aryl_halide 3",
  "aryl_halide 5", "aryl_halide 4", "aryl_halide 8", "aryl_halide 14", "aryl_halide 7",
  "aryl_halide 13", "aryl_halide 2", "aryl_halide 1", "aryl_halide 10")

ligand_columns <- c("ligand 4", "ligand 3", "ligand 1")

X_halide <-  xxxx[, halide_columns, drop = FALSE]

X_ligand <- xxxx[, ligand_columns, drop = FALSE]



# Step 1: Add a new column "aryl_halide 11"
X_halide <- cbind(X_halide, "aryl_halide 11" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_halide[X_halide[, "aryl_halide 1"] == -1, "aryl_halide 11"] <- 1

# Step 3: Replace all -1 with 0 in the entire matrix
X_halide[X_halide == -1] <- 0

# Assuming X_ligand is your matrix
# Step 1: Add a new column "aryl_halide 11"
X_ligand <- cbind(X_ligand, "ligand 2" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_ligand[X_ligand[, "ligand 1"] == -1, "ligand 2"] <- 1

# Step 3: Replace all -1 with 0 in the entire matrix
X_ligand[X_ligand == -1] <- 0

#Check the transformations worked
#rowSums( X_ligand ) 
#rowSums(X_halide)


print(dim(X_halide))

X_main <- cbind(X_halide, X_ligand)
dim(X_main)
rowSums(X_main)




#### PREPARE ALSO X_all_MAIN (i.e. get rid of -1 and add all columns #### (Think if this can be improved

X_all_main<-x.all ##have X_all_main for later

# Step 1: Add a new column "aryl_halide 11"
X_all_main <- cbind(X_all_main, "aryl_halide 11" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_all_main[X_all_main[, "aryl_halide 1"] == -1, "aryl_halide 11"] <- 1




# Step 1: Add a new column "aryl_halide 11"
X_all_main <- cbind(X_all_main, "ligand 2" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_all_main[X_all_main[, "ligand 1"] == -1, "ligand 2"] <- 1



# Step 1: Add a new column "aryl_halide 11"
X_all_main <- cbind(X_all_main, "additive 15" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_all_main[X_all_main[, "additive 1"] == -1, "additive 15"] <- 1



# Step 1: Add a new column "aryl_halide 11"
X_all_main <- cbind(X_all_main, "base 3" = 0)

# Step 2: Set values in "aryl_halide 11" column
X_all_main[X_all_main[, "base 1"] == -1, "base 3"] <- 1

# Step 3: Replace all -1 with 0 in the entire matrix
X_all_main[X_all_main == -1] <- 0

#Check the transformations worked
rowSums( X_all_main ) 
colnames(X_all_main)
X_all_main



#################### USE HIERNET PACKAGE ######################
library(Metrics)

library(hierNet)
library(caret)
library(dplyr)
library(Metrics)

names(y)[ncol(y)] <- "yield"
main_data <- cbind(X_main, y$yield)

dim(main_data)


names(main_data)[ncol(main_data)] <- "yield" #name the y column




##TRAIN TEST SPLIT
index <- createDataPartition(y = y$yield, p = 0.7, list = FALSE)
train_data <- main_data [index,]
test_data <- main_data [-index,]



# Separate X_train, X_test, y_train, y_test
X_train <- train_data[, -ncol(train_data)]
y_train <- train_data[, ncol(train_data)]
X_test <- test_data[, -ncol(test_data)]
y_test <- test_data[, ncol(test_data)]

y_train<-y_train*100
y_test<-y_test*100

print(dim(X_train))

print(dim(X_test))
print(length(y_train))
print(length(y_test))



#X_all= rbind(X_train, X_test)
#y_all=rbind(y_train, y_test)

#X_all




colnames(X_train)


##On train
fit=hierNet(X_train,y_train,lam=20, diagonal = FALSE)
yhat=predict(fit,X_train)
fit$bp
fit $bn
rmse(y_train, yhat)
r2(y_train, yhat)
#checkBlocks(fit$th,15,4) ##check if interations that should be 0 are 0 
fit
print(max(yhat))
max(y_train)
max(yhat)


## Do cross val then check the best on test
fit=hierNet.path(X_train,y_train, diagonal =  FALSE, trace = 0, minlam = 10, maxlam = 1000)

fitcv=hierNet.cv(fit,X_train ,y_train, nfolds = 2, trace = 1)
fitcv
fitcv$cv.err 
lamhat=fitcv$lamhat
lamhat

fit=hierNet(X_train,y_train, lam = lamhat, diagonal = FALSE)
yhat=predict(fit,X_test)
print(paste("rmse:",rmse(y_test, yhat)))
print(paste("r2:", r2(y_test, yhat)))
fit
checkBlocks(fit$th,15,4)

max(yhat)
max(y_test)


#### TRAIN A LINEAR REG TO SEE CONSISTENCY OF RESULTS ####
library(glmnet)


create_interactions <- function(X) {
  n_features <- ncol(X)
  interaction_terms <- matrix(0, nrow = nrow(X), ncol = n_features * (n_features - 1) / 2)
  col_counter <- 1
  
  for (i in 1:(n_features - 1)) {
    for (j in (i + 1):n_features) {
      interaction_terms[, col_counter] <- X[, i] * X[, j]
      col_counter <- col_counter + 1
    }
  }
  
  return(cbind(X, interaction_terms))
}

X_train_interactions <- create_interactions(X_train)
X_test_interactions <- create_interactions(X_test)

# Train linear regression model using glmnet with interaction terms
fit <- glmnet(X_train_interactions, y_train)

# Predict on training set
y_train_pred <- predict(fit, s = 0, newx = X_train_interactions)

# Evaluate R-squared on training set
r2_train <- r2(y_train,y_train_pred)
cat("R-squared on training set:", r2_train, "\n")

# Predict on testing set
y_test_pred <- predict(fit, s = 0, newx = X_test_interactions)

# Evaluate R-squared on testing set
r2_test <- r2(y_test,y_test_pred)
cat("R-squared on testing set:", r2_test, "\n")
###



#####################DO the analysis on whole data with pairwise interacions################################

index <- createDataPartition(y = y$yield, p = 0.7, list = FALSE)
train_data <- main_data [index,]
test_data <- main_data [-index,]



# Separate X_train, X_test, y_train, y_test
X_all_train <- X_all_main[index, ]
y_train <- y[index, ]
X_all_test <- X_all_main[-index,]
y_test <- y[-index, ]



y_train<-y_train*100
y_test<-y_test*100

max(y_train)

print(dim(X_all_train))

print(dim(X_all_test))
print(length(y_train))
print(length(y_test))


colnames(X_all_train)


##On train
fit=hierNet(X_all_train,y_train,lam=200000000000, diagonal = FALSE)
yhat=predict(fit,X_all_train)
fit$bp
rmse(y_train, yhat)
r2(y_train, yhat)
#checkBlocks(fit$th,15,4) ##check if interations that should be 0 are 0 
fit
print(max(yhat))
max(y_train)
max(yhat)


## Do cross val then check the best on test
fit=hierNet.path(X_train,y_train, diagonal =  FALSE, trace = 0, minlam = 10, maxlam = 1000)

fitcv=hierNet.cv(fit,X_train ,y_train, nfolds = 2, trace = 1)
fitcv
fitcv$cv.err 
lamhat=fitcv$lamhat
lamhat
### TAkes much in this case


lamhat=80
fit=hierNet(X_all_train,y_train, lam = lamhat, diagonal = FALSE)
yhat=predict(fit,X_all_test)
print(paste("rmse:",rmse(y_test, yhat)))
print(paste("r2:", r2(y_test, yhat)))
fit
#checkBlocks(fit$th,15,4)

max(yhat)
max(y_test)


################## DO THE SAME WITH MY HIERNET

source("Functions.R")

dim(X_train)[2]
dim(matrix(0,nrow = dim(X_train)[2], ncol = 1))
result<-WEAK_HIERNET (X=X_train, Beta_plus_init=matrix(0.3,nrow = dim(X_train)[2], ncol = 1), Beta_minus_init=matrix(0.1,nrow = dim(X_train)[2], ncol = 1), 
              Theta_init=matrix(0, ncol = dim(X_train)[2], nrow = dim(X_train)[2]), y=y_train, lambda=0, t=0.0002, tol=1e-8, 
              max_iter=250, eps=1e-8 ) 

beta_plus=result$Beta_hat_plus
beta_minus=result$Beta_hat_minus
Theta=result$Theta_hat

p <- ncol(X_train)
n<-nrow(X_train)
X <- scale(X_train)#standardize X
#CONSTRUCT Z
Z=t(apply(X, 1, function(x) outer(x, x, "*")))
Z <- scale(Z, center = TRUE, scale = FALSE) #center Z
Z=set_Z_values_to_zero(Z,p) #MAKE 0 cols for Xi Xi interaction
y_train <- scale(y_train, center = TRUE, scale = FALSE) #center y
y_train
y_train_pred
y_train_pred= X %*% (beta_plus - beta_minus) + Z %*% c(t(Theta)) / 2

print(Theta)
print(beta_minus)
print(beta_plus)

paste("r2 with my hiernet on train :", r2(y_train, y_train_pred))





############SAME BUT ON ALL DATA with 2 interactions

dim(matrix(0,nrow = dim(X_train)[2], ncol = 1))
result<-WEAK_HIERNET (X=X_all_train, Beta_plus_init=matrix(0.3,nrow = dim(X_all_train)[2], ncol = 1), Beta_minus_init=matrix(0.1,nrow = dim(X_all_train)[2], ncol = 1), 
                      Theta_init=matrix(0, ncol = dim(X_all_train)[2], nrow = dim(X_all_train)[2]), y=y_train, lambda=80, t=0.0001, tol=1e-6, 
                      max_iter=250, eps=1e-8 ) 

beta_plus=result$Beta_hat_plus
beta_minus=result$Beta_hat_minus
Theta=result$Theta_hat

p <- ncol(X_all_train)
n<-nrow(X_all_train)
X <- scale(X_all_train)#standardize X
#CONSTRUCT Z
Z=t(apply(X, 1, function(x) outer(x, x, "*")))
Z <- scale(Z, center = TRUE, scale = FALSE) #center Z
Z=set_Z_values_to_zero(Z,p) #MAKE 0 cols for Xi Xi interaction
y_train <- scale(y_train, center = TRUE, scale = FALSE) #center y
y_train
y_train_pred
y_train_pred= X %*% (beta_plus - beta_minus) + Z %*% c(t(Theta)) / 2

#### CHECK ON TEST
p <- ncol(X_all_test)
n<-nrow(X_all_test)
X <- scale(X_all_test)#standardize X
#CONSTRUCT Z
Z=t(apply(X, 1, function(x) outer(x, x, "*")))
Z <- scale(Z, center = TRUE, scale = FALSE) #center Z
Z=set_Z_values_to_zero(Z,p) #MAKE 0 cols for Xi Xi interaction
y_test <- scale(y_test, center = TRUE, scale = FALSE) #center y

y_test_pred= X %*% (beta_plus - beta_minus) + Z %*% c(t(Theta)) / 2



print(Theta)
print(beta_minus)
print(beta_plus)

paste("r2 with my hiernet on test with all data and 2 interactions :", r2(y_test, y_test_pred))




############################# USE MY CLASS ##########################################
source("WeakHierNet_Class.R")

Beta_plus_init=matrix(0,nrow = dim(X_all_train)[2], ncol = 1)
Beta_minus_init=matrix(0,nrow = dim(X_all_train)[2], ncol = 1)
Theta_init=matrix(0, ncol = dim(X_all_train)[2], nrow = dim(X_all_train)[2])
lambda=80
t=0.00001
tol = 1e-16

myWeakHierNet<-WeakHierNet (X=X_all_train, Beta_plus_init= Beta_plus_init, Beta_minus_init=Beta_minus_init, 
                      Theta_init = Theta_init, y=y_train, lambda=lambda, t=t, tol=tol, 
                      max_iter=150, eps=1e-8 ) 



# Fit the model
fitted=myWeakHierNet$fit(X=X_all_train, y=y_train, lambda=lambda, t = t, tol = tol, max_iter = 150, eps = 1e-8,
                         Beta_plus_init = Beta_plus_init,Beta_minus_init =  Beta_minus_init, Theta_init =  Theta_init)
fitted
# Make predictions
#y_pred=myWeakHierNet$predict(fitted, X_all_train)
#y_pred
#scale(y_train,center = TRUE, scale= FALSE)

myWeakHierNet$R2_score(self=fitted, new_X= as.matrix(X_all_test), y_true = y_test, verbose = TRUE)

###########################################################################################################





############################# USE MY CORRECTED CLASS ##########################################
source("WeakHierNet_Class_corrected.R")

Beta_plus_init=matrix(0,nrow = dim(X_all_train)[2], ncol = 1)
Beta_minus_init=matrix(0,nrow = dim(X_all_train)[2], ncol = 1)
Theta_init=matrix(0, ncol = dim(X_all_train)[2], nrow = dim(X_all_train)[2])
lambda=80000
t=0.00001
tol = 1e-5

myWeakHierNet<-WeakHierNet (X=X_all_train, Beta_plus_init= Beta_plus_init, Beta_minus_init=Beta_minus_init, 
                            Theta_init = Theta_init, y=y_train, lambda=lambda, t=t, tol=tol, 
                            max_iter=100, eps=1e-8 ) 



# Fit the model
fitted=myWeakHierNet$fit(X=X_all_train, y=y_train, lambda=lambda, t = t, tol = tol, max_iter = 100, eps = 1e-8,
                         Beta_plus_init = Beta_plus_init,Beta_minus_init =  Beta_minus_init, Theta_init =  Theta_init)
fitted
# Make predictions
#y_pred=myWeakHierNet$predict(fitted, X_all_train)
#y_pred
#scale(y_train,center = TRUE, scale= FALSE)

myWeakHierNet$R2_score(self=fitted, new_X= as.matrix(X_all_test), y_true = y_test, verbose = TRUE)

###########################################################################################################



###CONCLUSIONS 

##It seems that there are no problems due to considering all pairs interactions bc for high enough lambda tho ones that should be 0 by default go to 0
##It has around 0.56 r2 score on both training and test set and rmse around 0.18
## It works better than a linear reg that does not consider interactions. It works similar to linear reg with all interactions. 
## It works much better on the entire data (around r2 = 0.856)








########### CONTINUA CU #############


### Fa block diag si pt 4 si verifica cum merge la toate datele
### VEZI daca converge
#### FA TOTUL SI PT 2 LEVELS FIXED ?!
### VEZI CUM FACI SA IASA IN 0, 100 (Vezi cum e si in Paper)

### Treci la propria implementare












# Assuming main_data is your data matrix or data frame
if (any(is.na(X_train))) {
  cat("Missing values found in the data.\n")
} else {
  cat("No missing values found in the data.\n")
}

if (any(is.infinite(y_train)) || any(is.nan(y_train))) {
  cat("Infinite or NaN values found in the data.\n")
} else {
  cat("No infinite or NaN values found in the data.\n")
}




