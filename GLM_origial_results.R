#######################
## Data processing
#######################

# Plate 1.1
plate1.1 <- read.csv("yield_data\\plate1.1.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.1_pdt <- plate1.1$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.1_pdt))
dim(plate.data) <- c(24,16)
plate.data1.1 <- t(plate.data)

# Plate 1.2
plate1.2 <- read.csv("yield_data\\plate1.2.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.2_pdt <- plate1.2$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.2_pdt))
dim(plate.data) <- c(24,16)
plate.data1.2 <- t(plate.data)

# Plate 1.3
plate1.3 <- read.csv("yield_data\\plate1.3.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.3_pdt <- plate1.3$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.3_pdt))
dim(plate.data) <- c(24,16)
plate.data1.3 <- t(plate.data)

# Plate 1.4
plate1.4 <- read.csv("yield_data\\plate1.4.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate1.4_pdt <- plate1.4$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate1.4_pdt))
dim(plate.data) <- c(24,16)
plate.data1.4 <- t(plate.data)

# stitch Plate 1 together into one 32x48 matrix
plate1.top <- cbind(plate.data1.1, plate.data1.2)
plate1.bottom <- cbind(plate.data1.3, plate.data1.4)
plate1 <- rbind(plate1.top, plate1.bottom)

# Plate 2.1
plate2.1 <- read.csv("yield_data\\plate2.1.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.1_pdt <- plate2.1$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.1_pdt))
dim(plate.data) <- c(24,16)
plate.data2.1 <- t(plate.data)

# Plate 2.2
plate2.2 <- read.csv("yield_data\\plate2.2.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.2_pdt <- plate2.2$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.2_pdt))
dim(plate.data) <- c(24,16)
plate.data2.2 <- t(plate.data)

# Plate 2.3
plate2.3 <- read.csv("yield_data\\plate2.3.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.3_pdt <- plate2.3$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.3_pdt))
dim(plate.data) <- c(24,16)
plate.data2.3 <- t(plate.data)

# Plate 2.4
plate2.4 <- read.csv("yield_data\\plate2.4.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate2.4_pdt <- plate2.4$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate2.4_pdt))
dim(plate.data) <- c(24,16)
plate.data2.4 <- t(plate.data)

# stitch Plate 2 together into one 32x48 matrix
plate2.top <- cbind(plate.data2.1, plate.data2.2)
plate2.bottom <- cbind(plate.data2.3, plate.data2.4)
plate2 <- rbind(plate2.top, plate2.bottom)

# Plate 3.1
plate3.1 <- read.csv("yield_data\\plate3.1.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.1_pdt <- plate3.1$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.1_pdt))
dim(plate.data) <- c(24,16)
plate.data3.1 <- t(plate.data)

# Plate 3.2
plate3.2 <- read.csv("yield_data\\plate3.2.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.2_pdt <- plate3.2$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.2_pdt))
dim(plate.data) <- c(24,16)
plate.data3.2 <- t(plate.data)

# Plate 3.3
plate3.3 <- read.csv("yield_data\\plate3.3.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.3_pdt <- plate3.3$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.3_pdt))
dim(plate.data) <- c(24,16)
plate.data3.3 <- t(plate.data)

# Plate 3.4
plate3.4 <- read.csv("yield_data\\plate3.4.csv", header=TRUE, stringsAsFactors=FALSE, na.strings = "#DIV/0!")
plate3.4_pdt <- plate3.4$product_scaled[1:384]
plate.data <- as.matrix(as.numeric(plate3.4_pdt))
dim(plate.data) <- c(24,16)
plate.data3.4 <- t(plate.data)

# stitch Plate 3 together into one 32x48 matrix
plate3.top <- cbind(plate.data3.1, plate.data3.2)
plate3.bottom <- cbind(plate.data3.3, plate.data3.4)
plate3 <- rbind(plate3.top, plate3.bottom)

# Remove empty rows/cols
plate1_nocontrols <- plate1[c(-1,-5,-9,-13,-20,-24,-28,-32), c(-16,-32,-48)] 
plate2_nocontrols <- plate2[, c(-16,-32,-48)]
plate3_nocontrols <- plate3[, c(-16,-32,-48)]
plate1_nocontrols_v <- as.vector(t(plate1_nocontrols))
plate2_nocontrols_v <- as.vector(t(plate2_nocontrols))
plate3_nocontrols_v <- as.vector(t(plate3_nocontrols))
yield_data <- c(plate1_nocontrols_v, plate2_nocontrols_v, plate3_nocontrols_v)

# Load output table generated by python script
output.table <- read.csv("yield_data\\output_table.csv", header=TRUE)

# Scaled variables
y <- as.data.frame(yield_data[-which(is.na(yield_data))]/100)
x <- as.data.frame(output.table[-which(is.na(yield_data)),])
#x <- as.data.frame(scale(output.table[-which(is.na(yield_data)),]))
tt <- (1:length(y[,1]))/length(y)

# Add three artificial descriptors for additives
xc <- x
set.seed(2134)
c1 <- factor(xc[,1])
c2 <- factor(xc[,3])
c3 <- factor(xc[,4])
levels(c1) <- runif(22)
levels(c2) <- rnorm(22)
levels(c3) <- runif(22)
xc <- cbind(cbind(as.numeric(c1),as.numeric(c2),as.numeric(c3)),xc)
colnames(xc)[1:3] <- c("add_new1","add_new2","add_new3")

xs <- xc[,c(4,23,50,60)]
colnames(xs) <- c("additive","aryl_halide","base","ligand")

a <- rep(NA,ncol(xs))
for (i in 1:ncol(xs)) a[i] <- length(unique(xs[,i]))
xcf <- matrix(NA,nrow(xs),sum(a))
b <- cumsum(a)
colnames(xcf) <- rep(colnames(xs),times=a)
colnum <- order(unique(xs[,1]))
for (i in 2:ncol(xs)) colnum <- c(colnum,order(unique(xs[,i])))
colnames(xcf) <- paste(colnames(xcf),colnum)
for (i in 1:nrow(xs))
{
  for (j in 1:length(a))
  {
    res <- rep(0, a[j])
    where <- match( xs[i,j], unique(xs[,j]) )
    res[ where ] <- 1 
    xcf[i,(max(b[j-1],0)+1):b[j]] <- res
  }
}
for (i in 1:length(b))
{
  ind <- match(xcf[,b[i]],1)==1
  xcf[ind,(max(b[i-1],0)+1):b[i]] <- -1
}
xcf <- xcf[,-b]
x.all <- xcf

# Identify label ijkl for yield
for (ijkl in 1:length(tt)) {
  add.i <- colnames(x.all)[which(x.all[ijkl,]!=0)][1]
  add.I <- sum(grepl("additive",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (add.I>1) add.i <- "additive 0"
  ary.j <- colnames(x.all)[which(x.all[ijkl,]!=0)][1+add.I]
  ary.J <- sum(grepl("aryl_halide",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (ary.J>1) ary.j <- "aryl_halide 0"
  bas.k <- colnames(x.all)[which(x.all[ijkl,]!=0)][1+add.I+ary.J]
  bas.K <- sum(grepl("base",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (bas.K>1) bas.k <- "base 0"
  lig.l <- colnames(x.all)[which(x.all[ijkl,]!=0)][1+add.I+ary.J+bas.K]
  lig.L <- sum(grepl("ligand",colnames(x.all)[which(x.all[ijkl,]!=0)]))
  if (lig.L>1) lig.l <- "ligand 0"
  rownames(y)[ijkl] <- paste(add.i, ary.j, bas.k, lig.l, sep=":")
}
y.all <- y

# Mixed terms with 2-levels combinations
xx <- rep(1,nrow(xcf))
bb <- cumsum(a-1)
for (j in 1:3) {
  for (i in (max(bb[j-1],0)+1):bb[j]) {
    xxp <- xcf[,i]*xcf[,-c(1:bb[j])]
    colnames(xxp) <- paste(colnames(xcf)[i],colnames(xcf[,-c(1:bb[j])]),sep=":")
    xx <- cbind(xx,xxp)
  }
}
xx <- cbind(xcf,xx[,-1])
xx.all <- xx

# Mixed terms with 3-levels combinations
xcf1 <- xcf
colnames(xcf1) <- c(rep("additive",21),rep("aryl_halide",14),rep("base",2),rep("ligand",3))
xx1 <- xx[,-c(1:40)]

xxx <- rep(1,nrow(xcf))
ind <- rep(TRUE,ncol(xx1))
for (j in 1:2) {
  ind <- as.logical((!grepl(colnames(xcf1)[bb[j]],colnames(xx1)))*(ind))
  for (i in (max(bb[j-1],0)+1):bb[j]) {
    xxxp <- xcf[,i]*xx1[,ind]
    colnames(xxxp) <- paste(colnames(xcf)[i],colnames(xx1)[ind],sep=":")
    xxx <- cbind(xxx,xxxp)
  }
}
xxx <- cbind(xx,xxx[,-1])
xxx.all <- xxx

# Mixed terms with 4-levels combinations
xxx1 <- xxx[,-c(1:515)]

xxxx <- rep(NA,nrow(xcf))
for (i in 1:21) {
  xxxxp <- xcf[,i]*xxx1[,1597:1680]
  colnames(xxxxp) <- paste(colnames(xcf)[i],colnames(xxx1)[1597:1680],sep=":")
  xxxx <- cbind(xxxx,xxxxp)
}
xxxx <- cbind(xxx,xxxx[,-1])
xxxx.all <- xxxx



################################################################################
## Data Analysis on artificial ANOVA with two factors and two-way interactions  
################################################################################
library(Metrics)
library(caret)
library(dplyr)
library(Metrics)

######################### USEFUL FUNCTIONS######################################

store_vector_as_txt <- function(vector, column_names, folder_path, filename) {
  # Create the directory if it doesn't exist
  if (!file.exists(folder_path)) {
    dir.create(folder_path)
  }
  
  # Write vector and column names to a file
  write.table(data.frame(t(vector)), file = file.path(folder_path, filename),
              col.names = FALSE, row.names = FALSE, sep = ",")
  #write.table(data.frame(t(column_names)), file = file.path(folder_path, paste0(filename, "_columns")),
              #col.names = FALSE, row.names = FALSE, sep = ",")
}

read_vector_from_txt <- function(folder_path, filename, column_names, verbose=TRUE) {
  # Read the vector from file
  vector <- as.numeric(unlist(read.table(file.path(folder_path, filename), sep = ",")))
  

  
  if (verbose == TRUE){
  # Print column names and associated values
  cat(sprintf("%-12s%s\n", "Column", "Value"))
  for (i in 1:length(column_names)) {
    cat(sprintf("%-12s%s\n", paste(column_names[i], ": ", sep = ""), vector[i]))
  }
  }
  return(list(column_names = column_names, vector = vector))
}




get_elements <- function(column_names, vector_info) {
  # Extract vector from the result of read_vector_from_txt
  vector <- vector_info$vector
  names(vector) <- vector_info$column_names
  
  # Find indices of column names in the vector
  indices <- match(column_names, names(vector))
  
  # Get corresponding values from the vector
  values <- vector[indices]
  
  return(values)
}






################################################################################## Create X_all_train and X_all_test


print(dim(y))
X_all_main<-xx.all ##have X_all_main for later
print(dim(X_all_main))
dim(y)



index <- createDataPartition(y = y$yield, p = 0.7, list = FALSE)



# Separate X_train, X_test, y_train, y_test
X_all_train <- X_all_main[index, ]
y_train <- y[index, ]
X_all_test <- X_all_main[-index,]
y_test <- y[-index, ]


dim(X_all_train)

source('GLM_weak_HierNet_functions.R')




##################
columns_names<-colnames(X_all_train) 
main_effects<-columns_names[1:40]

#####CIORNA INDEX MAIN EFFECTS AND INTERACTIONs####

# Extract main effects from column names




# Function to get interactions containing a main effect
get_interactions <- function(main_effect, all_colnames) {
  # Case 1: Exactly main_effect
  idx_case1 <- grep(paste0("^", main_effect, "$"), all_colnames)
  
  # Case 2: main_effect followed by colon and anything
  idx_case2 <- grep(paste0("^", main_effect, ":.*"), all_colnames)
  
  # Case 3: Anything followed by colon and main_effect (with nothing after)
  idx_case3 <- grep(paste0(".*:", main_effect, "$"), all_colnames)
  
  # Merge indexes from all cases
  interactions <- union(idx_case1, union(idx_case2, idx_case3))
  
  return(list(main_effect = main_effect, interactions = interactions)) #interactions has all indices with first one being the main effect 
}



# Iterate over main effects and get interactions for each
main_effects_and_interactions <- lapply(main_effects, get_interactions, all_colnames = columns_names)

# Remove elements with no interactions
main_effects_and_interactions <- main_effects_and_interactions[sapply(main_effects_and_interactions, function(x) length(x$interactions) > 0)]


# Extract interactions from main_effects_and_interactions
list_of_interactions <- lapply(main_effects_and_interactions, function(x) x$interactions)

# Display the result
print("List that has lists like (main effect, interactions for that main effect), which is needed for the penalty. It has the positions of those interactions.")
print(list_of_interactions)


###USE FISHER SCORING FOR HIERARCHICAL LASSO


beta_result<-fisher_scoring_lasso(y=y_train, X=X_all_train, beta_init=lm(y_train~X_all_train)$coef, interactions=list_of_interactions, lambda=1,tol=0.01, max_iter=15) #The higher no of iters the better the result but takes loong
beta_result<-beta_result$beta.hat
pred_train<-sapply(as.vector(as.matrix(X_all_train)%*%beta_result[-1]+beta_result[1]), my_k_prime)
pred_test<-sapply(as.vector(as.matrix(X_all_test)%*%beta_result[-1]+beta_result[1]), my_k_prime)
print("rmse mine:")
print(sqrt(mean((pred_train*100-y_train*100)^2)))
print('r2 mine')
print(r2(y_train, pred_train))
print(r2(y_test, pred_test))

plot(pred_test,y_test)

#beta_result
print(sum(abs(beta_result)<=1e-5))
#################################################


r_2way_train<-y_train-pred_train
r_2way_test<-y_test-pred_test

####HOW TO STORE THE RESULTS ######################################################################


##FILENAME AND FOLDER PATH
folder_path <- 'Results'
filename <- 'GLM_lmd0.1.txt'

#STORE
#store_vector_as_txt(vector=beta_result, column_names=colnames(X_all_train), folder_path=folder_path, filename=filename)


#LOAD AGAIN AND USE
beta_hat<-read_vector_from_txt(folder_path, filename, column_names = colnames(X_all_train))$vector
y_pred_train<-sapply(as.vector(as.matrix(X_all_train)%*%beta_hat[-1]+beta_hat[1]), my_k_prime)
y_pred_test<-sapply(as.vector(as.matrix(X_all_test)%*%beta_hat[-1]+beta_hat[1]), my_k_prime)

#get_elements(c('base 1', 'additive 17', 'base 2:ligand 3'), read_vector_from_txt(folder_path, filename, column_names = colnames(X_all_train)))


r_2way_train<-y_train-y_pred_train
r_2way_test<-y_test-y_pred_test

mean(r_2way_test)
mean(r_2way_train)

print(mean(y_test))

###PRINT SCORES
print("rmse mine:")
print(sqrt(mean((pred_train*100-y_train*100)^2)))
print('r2 mine')
print(r2(y_train, y_pred_train))
print(r2(y_test, y_pred_test))
print(sum(abs(beta_hat)<=1e-5))

plot(y_test, pred_test)

####################### USE 3WAY SEQ on reisduals #############################





X_3way<-xxx.all
X_3way_train<-X_3way[index,c(516:2195)]
X_3way_test<-X_3way[-index,c(516:2195)]




################ fit lasso model on X3way#######################


library(glmnet)
# Fit Lasso model
lasso_model <- glmnet(x = X_3way_train, y = r_2way_train, alpha = 1, lambda = 0.003)
psi_vec_init<-array(coef(lasso_model)[2:length(coef(lasso_model))])
coef(lasso_model)
# Predictions for training data
train_predictions_3way <- predict(lasso_model, newx = X_3way_train)

# Predictions for test data
test_predictions_3way <- predict(lasso_model, newx = X_3way_test)

print(r2(r_2way_train,train_predictions_3way))
print(r2(r_2way_test,test_predictions_3way))

print(mean(r_2way_train))

#y_pred_test<-myWeakHierNet$predict(self=fitted, X_all_test)
#y_pred_train<-myWeakHierNet$predict(self=fitted, X_all_train)


#print("scores 2 way train test")
#print(r2(y_train, y_pred_train+mean(y_train)))
#print(r2(y_test, y_pred_test+mean(y_train)))

#print("scores 3 way train test")
print(r2(y_train, y_pred_train + train_predictions_3way))
print(r2(y_test, y_pred_test + test_predictions_3way))













### Fit my WEAKHIERNET_SEQ for 3 way ##############################
source("WeakHierNet_Class_sequential.R")


get_thetabound_from_theta_hat<-function(theta_hat,l1=21,l2=14,l3=2,l4=3)
{
  theta_bound<-matrix(0,l1+l2+l3+l4, l1+l2+l3+l4)
  
  for (index in c(1: (l1*(l2+l3+l4) +l2*(l3+l4) + l3*l4) ) ){
    #print(index)
  
  
  if ( index<=l1*(l2+l3+l4) ) #case 1 and case 2: additive + aryl-halide/base/lig
    
  {x<- floor((index-1)/(l2+l3+l4))+1
    y<- index- (x-1)* (l2+l3+l4) +l1
    theta_bound[x,y]<-theta_hat[index]} #not over 2 because the other is 0 i.e. theta[y,x]
        
  
 
  if (index>l1*(l2+l3+l4)  & index<= l1*(l2+l3+l4) +l2*(l3+l4) ) #x aryl-halide+ base/lig
   { x<- floor( (index-l1*(l2+l3+l4)-1)/(l3+l4)) + (l1+1)
    y<- index- l1* (l2+l3+l4) - (x-1-l1) *(l3+l4) + (l1+l2)
    theta_bound[x,y]<-theta_hat[index]}
  
  if (index> l1*(l2+l3+l4) +l2*(l3+l4) ) #x base+lig
  { x<- floor( (  index-l1*(l2+l3+l4) -l2*(l3+l4) -1 )/l4) + l1+l2+1
    y<- index- l1* (l2+l3+l4) - l2 *(l3+l4) + - (x-1-l1-l2)*l4   +(l1+l2+l3)
    theta_bound[x,y]<-theta_hat[index]}
  }
  
  return(theta_bound)
  
}


get_psi_from_psi_vec<-function(psi_vec,l1=21,l2=14, l3=2,l4=3)
{ counter<-1
  psi<-array(0,dim=(c(40,40,40)))
  
  ### CASE 1+case 2 have additive, aryl halide and anything else
  for (i in c(1:l1)) { #add
    for (j in c((l1+1):(l1+l2) ) ) { #halide
      for (k in c( (l1+l2+1): (l1+l2+l3+l4) ) ) {  #base\lig
        #cat("i:", i, ", j:", j, ", k:", k ,'\n')
        psi[i,j,k]<-psi_vec[counter]/6
        psi[i,k,j]<-psi_vec[counter]/6
        psi[k,i,j]<-psi_vec[counter]/6
        psi[k,j,i]<-psi_vec[counter]/6
        psi[j,i,k]<-psi_vec[counter]/6
        psi[j,k,i]<-psi_vec[counter]/6
        counter<-counter+1
      }}} ##case 1 : add, aryl-halide base/lig

### CASE 3 have additive,  base, ligand
 for (i in c(1:l1)) { #add
   for (j in c((l1+l2+1):(l1+l2+l3) ) ) { #base
     for (k in c( (l1+l2+l3+1): (l1+l2+l3+l4) ) ) {  #ligand
      #cat("i:", i, ", j:", j, ", k:", k ,'\n')
       psi[i,j,k]<-psi_vec[counter]/6
       psi[i,k,j]<-psi_vec[counter]/6
       psi[k,i,j]<-psi_vec[counter]/6
       psi[k,j,i]<-psi_vec[counter]/6
       psi[j,i,k]<-psi_vec[counter]/6
       psi[j,k,i]<-psi_vec[counter]/6
       counter<-counter+1
     }}}

### CASE 4 have halide,  base, ligand
for (i in c((l1+1):(l1+l2)) ) { #halide
  for (j in c((l1+l2+1):(l1+l2+l3) ) ) { #base
    for (k in c( (l1+l2+l3+1): (l1+l2+l3+l4) ) ) {  #ligand
      psi[i,j,k]<-psi_vec[counter]/6
      psi[i,k,j]<-psi_vec[counter]/6
      psi[k,i,j]<-psi_vec[counter]/6
      psi[k,j,i]<-psi_vec[counter]/6
      psi[j,i,k]<-psi_vec[counter]/6
      psi[j,k,i]<-psi_vec[counter]/6
      counter<-counter+1
    }}}
  print(counter)
  return(psi)
  }
 
#mhat<-array(0,24)
#mhat[2]=2
#mhat[1]=1
#mhat[24]=24
#mhat[5]=5
#get_thetabound_from_theta_hat(mhat,l1=2,l2=2,l3=2,l4=2) 






lambda <-1e1
t<-2e-6+5e-7
eps=1e-8
#psi_init<-array(rnorm(40*40*40, mean = 0, sd = 2), dim = c(40,40,40))
psi_init<-get_psi_from_psi_vec(psi_vec_init)

#print(dim(x.all))

#print(length(beta_hat[42:length(beta_hat)]))

#print(dim(X_3way_train))
#print(dim(X_all_main))

###DO PROPER THETA BOUND##################!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
#theta_bound<- matrix(20,nrow=40,ncol=40) ###de verificat#########################
theta_bound<-  ( get_thetabound_from_theta_hat(beta_hat[42:length(beta_hat)]) +t(get_thetabound_from_theta_hat(beta_hat[42:length(beta_hat)])) )/2
min(get_thetabound_from_theta_hat(beta_hat[42:length(beta_hat)]))
#theta_bound<-matrix(0.2,40,40)
max(theta_bound)
max(abs(r_2way_train))
# Example usage:

# Create an instance of the WeakHierNet class
myWeakHierNet_seq <- WeakHierNet_seq(X=X_3way_train, psi_init=psi_init, y=r_2way_train, theta_bound=theta_bound, lambda=lambda, t=t, tol=5e-8, max_iter=900, eps=1e-8,
                                     l1=21,l2=14,l3=2,l4=3)



# Fit the model
fitted=myWeakHierNet_seq$fit(X=X_3way_train, psi_init=psi_init, y=r_2way_train, theta_bound=theta_bound, lambda=lambda, t=t, tol=1e-8, max_iter=900, 
                             eps=1e-8,l1=21,l2=14,l3=2,l4=3)
#print(fitted$vec_psi_hat)
print(max(colSums(abs(fitted$psi_hat))))
#print(fitted$psi_hat)
sum(abs(fitted$vec_psi_hat)==0)
fitted$vec_psi_hat
mean(r_2way_train)
mean(r_2way_test)
# Make predictions
new_X <- X_3way_test
pred_train<- myWeakHierNet_seq$pred(fitted,X_3way_train)
pred_test<- myWeakHierNet_seq$pred(fitted,X_3way_test)
print(r2(r_2way_train,pred_train))
print(r2(r_2way_test,pred_test))

print(myWeakHierNet_seq$R2_score(fitted,X_3way_train,r_2way_train))
print(myWeakHierNet_seq$R2_score(fitted,X_3way_test,r_2way_test))

print(r2(y_train, y_pred_train))
print(r2(y_train, y_pred_train+pred_train))
print(r2(y_test, y_pred_test))
print(r2(y_test, y_pred_test+pred_test))




######################################################33








#### CONLUSION####

###TAKES A LOT
####NEEDS A LOT OF ITERS FOR CONVERGENCE
####MAYBE FIND BETTER WAY TO OPTIMIZE BETA







